{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Shapefile Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import geopandas as gp\n",
    "import numpy as np\n",
    "import nafot\n",
    "import shapely\n",
    "from shapely.geometry import Point\n",
    "from shapely.ops import cascaded_union\n",
    "from matplotlib import pyplot as plt\n",
    "import matplotlib\n",
    "import os\n",
    "matplotlib.style.use('ggplot')\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load statistical area data and shapefile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# stat_area_df2 = gp.read_file('../data/_lamas/50400_stat_area_2008 - Copy/stat_2008_NEW_04Nov_1335.shp',\n",
    "#                             encoding='windows-1255')\n",
    "stat_area_df = nafot.borders.stat_area_wgs_df.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load extra data about the statistical areas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "extra_df = pd.read_excel('../data/_lamas/50401_population/Pop_Sex_Age_Religion - edited.xlsx',\n",
    "                           encoding='windows-1255')\n",
    "\n",
    "# Get only the wanted columns\n",
    "extra_df = extra_df[['SEMEL_YISHUV', 'STAT08','DistrictCode', 'DistrictHeb',\n",
    "       'SubDistrictCode', 'SubDistrictHeb', 'MetrCode', 'MetrHeb', 'pop_thou']]\n",
    "\n",
    "# Convert STAT08 into an integer\n",
    "extra_df['STAT08'] = extra_df.STAT08.astype('int64', copy=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>OBJECTID</th>\n",
       "      <th>SEMEL_YISH</th>\n",
       "      <th>STAT08</th>\n",
       "      <th>Shape_Area</th>\n",
       "      <th>Shape_Leng</th>\n",
       "      <th>Shem_Yis_1</th>\n",
       "      <th>Shem_Yishu</th>\n",
       "      <th>YISHUV_STA</th>\n",
       "      <th>geometry</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>-2</td>\n",
       "      <td>0</td>\n",
       "      <td>4.622823e+08</td>\n",
       "      <td>724681.884774</td>\n",
       "      <td>None</td>\n",
       "      <td>ùèç ììà ùéôåè</td>\n",
       "      <td>0</td>\n",
       "      <td>(POLYGON ((35.00832616096807 31.12433357493895...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>6.802526e+06</td>\n",
       "      <td>11591.466653</td>\n",
       "      <td>SHAHAR</td>\n",
       "      <td>ùçø</td>\n",
       "      <td>70001</td>\n",
       "      <td>POLYGON ((34.73932928249113 31.62604186681884,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>4.445150e+05</td>\n",
       "      <td>2981.465220</td>\n",
       "      <td>TIROSH</td>\n",
       "      <td>úéøåù</td>\n",
       "      <td>100001</td>\n",
       "      <td>POLYGON ((34.8878463564387 31.75143638736428, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>5.983378e+06</td>\n",
       "      <td>11808.357935</td>\n",
       "      <td>NIR HEN</td>\n",
       "      <td>ðéø çï</td>\n",
       "      <td>110001</td>\n",
       "      <td>POLYGON ((34.72779348911466 31.60676610854767,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>1.780427e+07</td>\n",
       "      <td>17954.580825</td>\n",
       "      <td>HAZEVA</td>\n",
       "      <td>çöáä</td>\n",
       "      <td>130001</td>\n",
       "      <td>POLYGON ((35.28651769274753 30.74930282971737,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   OBJECTID  SEMEL_YISH  STAT08    Shape_Area     Shape_Leng Shem_Yis_1  \\\n",
       "0         1          -2       0  4.622823e+08  724681.884774       None   \n",
       "1         2           7       1  6.802526e+06   11591.466653     SHAHAR   \n",
       "2         3          10       1  4.445150e+05    2981.465220     TIROSH   \n",
       "3         4          11       1  5.983378e+06   11808.357935    NIR HEN   \n",
       "4         5          13       1  1.780427e+07   17954.580825     HAZEVA   \n",
       "\n",
       "      Shem_Yishu  YISHUV_STA  \\\n",
       "0  ùèç ììà ùéôåè           0   \n",
       "1            ùçø       70001   \n",
       "2          úéøåù      100001   \n",
       "3         ðéø çï      110001   \n",
       "4           çöáä      130001   \n",
       "\n",
       "                                            geometry  \n",
       "0  (POLYGON ((35.00832616096807 31.12433357493895...  \n",
       "1  POLYGON ((34.73932928249113 31.62604186681884,...  \n",
       "2  POLYGON ((34.8878463564387 31.75143638736428, ...  \n",
       "3  POLYGON ((34.72779348911466 31.60676610854767,...  \n",
       "4  POLYGON ((35.28651769274753 30.74930282971737,...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stat_area_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a distinctive id for a statistical area\n",
    "(By concatenating SEMEL YISHUV and STAT08)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create the ID column in the shapefile df (and set it as an index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "stat_area_df['stat_id'] = stat_area_df.apply(lambda row: int(str(row['SEMEL_YISH']).strip() +\n",
    "                                        str(row['STAT08']).strip()), axis=1)\n",
    "stat_area_df.set_index('stat_id', inplace=True, verify_integrity=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create the ID column in the extra data df (and set it as an index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "extra_df['stat_id'] = extra_df.apply(lambda row: int(str(row['SEMEL_YISHUV']).strip() +\n",
    "                                        str(row['STAT08']).strip()), axis=1)\n",
    "extra_df.set_index('stat_id', inplace=True, verify_integrity=True)\n",
    "extra_df.drop(['SEMEL_YISHUV', 'STAT08'], inplace=True, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Join the data frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "stat_area_df_joined = stat_area_df.join(extra_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save as a new GeoDataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf = gp.GeoDataFrame(stat_area_df_joined, geometry='geometry')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove no jurisdiction area\n",
    "gdf.drop(-20, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Aggregated Polygons"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Districts polygons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get all the districts codes\n",
    "district_codes = pd.unique(gdf[~gdf.DistrictCode.isnull()].DistrictCode)\n",
    "\n",
    "# Create a dictionary of the districts polygons\n",
    "district_polygons = {code : cascaded_union(gdf[gdf.DistrictCode == code].geometry.values) for code in district_codes}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create SubDistricts polygons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get all the subdistricts codes\n",
    "subdistrict_codes = pd.unique(gdf[~gdf.SubDistrictCode.isnull()].SubDistrictCode)\n",
    "\n",
    "# Create a dictionary of the subdistricts polygons\n",
    "subdistrict_polygons = {code : cascaded_union(gdf[gdf.SubDistrictCode == code].geometry.values) for code in subdistrict_codes}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Yeshuvim polygons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Get all the districts codes\n",
    "yeshuvim_codes = pd.unique(gdf[~gdf.SEMEL_YISH.isnull()].SEMEL_YISH)\n",
    "\n",
    "# Create a dictionary of the districts polygons\n",
    "yeshuvim_polygons = {code : cascaded_union(gdf[gdf.SEMEL_YISH == code].geometry.values) for code in yeshuvim_codes}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Statistical areas without hierarchy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "single_stat_codes = gdf[gdf.DistrictCode.isnull()].index.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create GeoDataFrames (For each level)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create District GeoDataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "districts_gdf = pd.DataFrame(district_codes, columns=['DistrictCode'])\n",
    "districts_gdf['geometry'] = districts_gdf.apply(lambda row: district_polygons[row.DistrictCode], axis=1)\n",
    "districts_gdf.set_index('DistrictCode', inplace=True)\n",
    "districts_gdf = gp.GeoDataFrame(districts_gdf, geometry='geometry')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create SubDistrict GeoDataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "subdistricts_gdf = pd.DataFrame(subdistrict_codes, columns=['SubDistrictCode'])\n",
    "subdistricts_gdf['geometry'] = subdistricts_gdf.apply(lambda row: subdistrict_polygons[row.SubDistrictCode], axis=1)\n",
    "subdistricts_gdf.set_index('SubDistrictCode', inplace=True)\n",
    "subdistricts_gdf = gp.GeoDataFrame(subdistricts_gdf, geometry='geometry')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Yeshuvim GeoDataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "yeshuvim_gdf = pd.DataFrame(yeshuvim_codes, columns=['SEMEL_YISH'])\n",
    "yeshuvim_gdf['geometry'] = yeshuvim_gdf.apply(lambda row: yeshuvim_polygons[row.SEMEL_YISH], axis=1)\n",
    "yeshuvim_gdf.set_index('SEMEL_YISH', inplace=True)\n",
    "yeshuvim_gdf = gp.GeoDataFrame(yeshuvim_gdf, geometry='geometry')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Statistical Areas GeoDataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "stat_areas_gdf = gdf[['geometry']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Hierarchical lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create a dict containing a list of SubDistrict for each District\n",
    "districts_sub = {code : pd.unique(gdf[gdf.DistrictCode == code].SubDistrictCode.values) for code in district_codes}\n",
    "\n",
    "# Create a dict containing a list of Yeshuvim for each SubDistrict\n",
    "subdistrict_yesuvim = {code : pd.unique(gdf[gdf.SubDistrictCode == code].SEMEL_YISH.values) for code in subdistrict_codes}\n",
    "\n",
    "# Create a dict containing a list of Statistical areas for each Yeshuv\n",
    "yeshuvim_stat = {code : pd.unique(gdf[gdf.SEMEL_YISH == code].index.values) for code in yeshuvim_codes}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "districts_stat = {code : pd.unique(gdf[gdf.DistrictCode == code].index.values) for code in district_codes}\n",
    "subdistrict_stat = {code : pd.unique(gdf[gdf.SubDistrictCode == code].index.values) for code in subdistrict_codes}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hierarchical Search\n",
    "#### Districts -> Subdistricts -> Yeshuvim -> Statistical Areas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### First Version - For Loops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_stat_area_v1(longtitude, latitude):\n",
    "# def get_stat_area(point):\n",
    "    # Create a point object\n",
    "    point = Point(longtitude, latitude)\n",
    "    \n",
    "    # Get the district\n",
    "    district = which_district_v1(point)\n",
    "    # Get the subdistrict\n",
    "    subdistrict = which_sub_district_v1(point, district)\n",
    "    # Get the yeshuv\n",
    "    yeshuv = which_yeshuv_v1(point, subdistrict)\n",
    "    # Get the stat area\n",
    "    stat_area = which_stat_v1(point, yeshuv)\n",
    "    \n",
    "    return stat_area                 \n",
    "                  \n",
    "def which_district_v1(point):\n",
    "    # Go over the districts\n",
    "    for i, poly in districts_gdf.itertuples():\n",
    "        if poly.contains(point):\n",
    "            return i\n",
    "\n",
    "def which_sub_district_v1(point, district=None): \n",
    "    # Get subdistricts to check\n",
    "    if district:\n",
    "        subdistricts = subdistricts_gdf.loc[districts_sub[district]]\n",
    "    else:\n",
    "        subdistricts = subdistricts_gdf\n",
    "    \n",
    "    # Go over the subdistricts\n",
    "    for i, poly in subdistricts.itertuples():\n",
    "        if poly.contains(point):\n",
    "            return i\n",
    "        \n",
    "def which_yeshuv_v1(point, subdistrict=None):\n",
    "    # Get yeshuvim to check\n",
    "    if subdistrict:\n",
    "        yeshuvim = yeshuvim_gdf.loc[subdistrict_yesuvim[subdistrict]]\n",
    "    else:\n",
    "        yeshuvim = yeshuvim_gdf\n",
    "    \n",
    "    # Go over the yeshuvim\n",
    "    for i, poly in yeshuvim.itertuples():\n",
    "        if poly.contains(point):\n",
    "            return i\n",
    "        \n",
    "def which_stat_v1(point, yeshuv=None):\n",
    "    # Get subdistricts to check\n",
    "    if yeshuv:\n",
    "        stat_areas = stat_areas_gdf.loc[yeshuvim_stat[yeshuv]]\n",
    "    else:\n",
    "        stat_areas = stat_areas_gdf\n",
    "    \n",
    "    # Go over the stat_areas\n",
    "    for i, poly in stat_areas.itertuples():\n",
    "        if poly.contains(point):\n",
    "            return i"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Second Version - sliced GeoDataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_stat_area_v2(longtitude, latitude):\n",
    "# def get_stat_area(point):\n",
    "    # Create a point object\n",
    "    point = Point(longtitude, latitude)\n",
    "    \n",
    "    # Get the district\n",
    "    district = which_district_v2(point)\n",
    "    # Get the subdistrict\n",
    "    subdistrict = which_sub_district_v2(point, district)\n",
    "    # Get the yeshuv\n",
    "    yeshuv = which_yeshuv_v2(point, subdistrict)\n",
    "    # Get the stat area\n",
    "    stat_area = which_stat_v2(point, yeshuv)\n",
    "    \n",
    "    return stat_area\n",
    "                                    \n",
    "def which_district_v2(point):\n",
    "    district = districts_gdf[districts_gdf.contains(point)]\n",
    "    \n",
    "    if district.size > 0:\n",
    "        return district.index[0]\n",
    "    \n",
    "def which_sub_district_v2(point, district=None): \n",
    "    # Get subdistricts to check\n",
    "    if district:\n",
    "        subdistricts = subdistricts_gdf.loc[districts_sub[district]]\n",
    "    else:\n",
    "        subdistricts = subdistricts_gdf\n",
    "    \n",
    "    subdistrict = subdistricts[subdistricts.contains(point)]\n",
    "    \n",
    "    if subdistrict.size > 0:\n",
    "        return subdistrict.index[0]\n",
    "        \n",
    "def which_yeshuv_v2(point, subdistrict=None):\n",
    "    # Get yeshuvim to check\n",
    "    if subdistrict:\n",
    "        yeshuvim = yeshuvim_gdf.loc[subdistrict_yesuvim[subdistrict]]\n",
    "    else:\n",
    "        yeshuvim = yeshuvim_gdf\n",
    "    \n",
    "    yeshuv = yeshuvim[yeshuvim.contains(point)]\n",
    "    \n",
    "    if yeshuv.size > 0:\n",
    "        return yeshuv.index[0]\n",
    "        \n",
    "def which_stat_v2(point, yeshuv=None):\n",
    "    # Get subdistricts to check\n",
    "    if yeshuv:\n",
    "        stat_areas = stat_areas_gdf.loc[yeshuvim_stat[yeshuv]]\n",
    "    else:\n",
    "        stat_areas = stat_areas_gdf\n",
    "    \n",
    "    stat_area = stat_areas[stat_areas.contains(point)]\n",
    "    \n",
    "    if stat_area.size > 0:\n",
    "        return stat_area.index[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Third Version - Preprocessed GeoDataframes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create hierarchical GeoDataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Subdistricts GeoDataframes by districts\n",
    "districts_sub_gdf = {district : subdistricts_gdf.loc[districts_sub[district]].copy() for district in district_codes}\n",
    "\n",
    "# Yeshuvim GeoDataframes by subdistricts\n",
    "subdistrict_yesuvim_gdf = {subdistrict : yeshuvim_gdf.loc[subdistrict_yesuvim[subdistrict]].copy()\n",
    "                           for subdistrict in subdistrict_codes}\n",
    "\n",
    "# Statistical areas GeoDataframes by yeshuvim\n",
    "yeshuvim_stat_gdf = {yeshuv : stat_areas_gdf.loc[yeshuvim_stat[yeshuv]].copy()\n",
    "                           for yeshuv in yeshuvim_codes}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_stat_area_v3(longtitude, latitude):\n",
    "# def get_stat_area(point):\n",
    "    # Create a point object\n",
    "    point = Point(longtitude, latitude)\n",
    "    \n",
    "    # Get the district\n",
    "    district = which_district_v3(point)\n",
    "    # Get the subdistrict\n",
    "    subdistrict = which_sub_district_v3(point, district)\n",
    "    # Get the yeshuv\n",
    "    yeshuv = which_yeshuv_v3(point, subdistrict)\n",
    "    # Get the stat area\n",
    "    stat_area = which_stat_v3(point, yeshuv)\n",
    "    \n",
    "    return stat_area\n",
    "                                    \n",
    "def which_district_v3(point):\n",
    "    district = districts_gdf[districts_gdf.contains(point)]\n",
    "    \n",
    "    if district.size > 0:\n",
    "        return district.index[0]\n",
    "    \n",
    "def which_sub_district_v3(point, district=None): \n",
    "    # Get subdistricts to check\n",
    "    if district:\n",
    "        subdistricts = districts_sub_gdf[district]\n",
    "    else:\n",
    "        subdistricts = subdistricts_gdf\n",
    "    \n",
    "    subdistrict = subdistricts[subdistricts.contains(point)]\n",
    "    \n",
    "    if subdistrict.size > 0:\n",
    "        return subdistrict.index[0]\n",
    "        \n",
    "def which_yeshuv_v3(point, subdistrict=None):\n",
    "    # Get yeshuvim to check\n",
    "    if subdistrict:\n",
    "        yeshuvim = subdistrict_yesuvim_gdf[subdistrict]\n",
    "    else:\n",
    "        yeshuvim = yeshuvim_gdf\n",
    "    \n",
    "    yeshuv = yeshuvim[yeshuvim.contains(point)]\n",
    "    \n",
    "    if yeshuv.size > 0:\n",
    "        return yeshuv.index[0]\n",
    "        \n",
    "def which_stat_v3(point, yeshuv=None):\n",
    "    # Get subdistricts to check\n",
    "    if yeshuv:\n",
    "        stat_areas = yeshuvim_stat_gdf[yeshuv]\n",
    "    else:\n",
    "        stat_areas = stat_areas_gdf\n",
    "    \n",
    "    stat_area = stat_areas[stat_areas.contains(point)]\n",
    "    \n",
    "    if stat_area.size > 0:\n",
    "        return stat_area.index[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fourth Version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_stat_area_v4(longtitude, latitude):\n",
    "# def get_stat_area(point):\n",
    "    # Create a point object\n",
    "    point = Point(longtitude, latitude)\n",
    "    \n",
    "    # Get the district\n",
    "    district = which_district_v1(point)\n",
    "\n",
    "    # Get the stat area\n",
    "    stat_area = which_stat_v4(point, district)\n",
    "    \n",
    "    return stat_area\n",
    "\n",
    "def which_stat_v4(point, district=None):\n",
    "    # Get subdistricts to check\n",
    "    if district:\n",
    "        stat_areas = stat_areas_gdf.loc[districts_stat[district]]\n",
    "    else:\n",
    "        stat_areas = stat_areas_gdf\n",
    "    \n",
    "    # Go over the stat_areas\n",
    "    for i, poly in stat_areas.itertuples():\n",
    "        global counter\n",
    "        if poly.contains(point):\n",
    "            return i"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fifth Version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_stat_area_v5(longtitude, latitude):\n",
    "# def get_stat_area(point):\n",
    "    # Create a point object\n",
    "    point = Point(longtitude, latitude)\n",
    "    \n",
    "    # Get the district\n",
    "    subdistrict = which_sub_district_v1(point)\n",
    "\n",
    "    # Get the stat area\n",
    "    stat_area = which_stat_v5(point, subdistrict)\n",
    "    \n",
    "    return stat_area\n",
    "\n",
    "def which_stat_v5(point, subdistrict=None):\n",
    "    # Get subdistricts to check\n",
    "    if subdistrict:\n",
    "        stat_areas = stat_areas_gdf.loc[subdistrict_stat[subdistrict]]\n",
    "    else:\n",
    "        stat_areas = stat_areas_gdf\n",
    "    \n",
    "    # Go over the stat_areas\n",
    "    for i, poly in stat_areas.itertuples():\n",
    "        if poly.contains(point):\n",
    "            return i"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sixth Version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_stat_area_v6(longtitude, latitude):\n",
    "    point = Point(longtitude, latitude)\n",
    "    \n",
    "    # Get the district\n",
    "    yeshuv = which_yeshuv_v6(point)\n",
    "\n",
    "    # Get the stat area\n",
    "    stat_area = which_stat_v6(point, yeshuv)\n",
    "    \n",
    "    return stat_area\n",
    "\n",
    "def which_yeshuv_v6(point):\n",
    "    # Go over the yeshuvim\n",
    "    for i, poly in yeshuvim_gdf.itertuples():\n",
    "        if poly.contains(point):\n",
    "            return i\n",
    "\n",
    "def which_stat_v6(point, yeshuv=None):\n",
    "    # Get subdistricts to check\n",
    "    if yeshuv:\n",
    "        stat_areas = stat_areas_gdf.loc[yeshuvim_stat[yeshuv]]\n",
    "    else:\n",
    "        stat_areas = stat_areas_gdf.loc[single_stat_codes]\n",
    "    \n",
    "    # Go over the stat_areas\n",
    "    for i, poly in stat_areas.itertuples():\n",
    "        if poly.contains(point):\n",
    "            return i"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Seventh Version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "subdistrict_ids = subdistricts_gdf.index.copy().values\n",
    "subdistrict_polys = subdistricts_gdf.geometry.copy().values\n",
    "\n",
    "yeshuvim_ids = yeshuvim_gdf.index.copy().values\n",
    "yeshuvim_polys = yeshuvim_gdf.geometry.copy().values\n",
    "\n",
    "stat_ids = stat_areas_gdf.index.copy().values\n",
    "stat_polys = stat_areas_gdf.geometry.copy().values\n",
    "\n",
    "# stat areas without district\n",
    "stat_polys_singles = stat_polys.copy()[[np.where(stat_ids == code)[0][0] for code in single_stat_codes]]\n",
    "\n",
    "yeshuvim_stat_polys = {yeshuv : stat_areas_gdf.geometry.loc[yeshuvim_stat[yeshuv]].copy().values\n",
    "                           for yeshuv in yeshuvim_codes}\n",
    "\n",
    "subdistrict_stat_polys = {subdistrict : stat_areas_gdf.geometry.loc[subdistrict_stat[subdistrict]].copy().values\n",
    "                           for subdistrict in subdistrict_codes}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_stat_area_v7(longtitude, latitude):\n",
    "    point = Point(longtitude, latitude)\n",
    "    \n",
    "    # Get the yeshuv\n",
    "    yeshuv = which_yeshuv_v7(point)\n",
    "    \n",
    "    if yeshuv:\n",
    "        # Get the stat area\n",
    "        stat_area = which_stat_v7(point, yeshuv)\n",
    "        return stat_area\n",
    "\n",
    "def which_yeshuv_v7(point):\n",
    "    # Go over the yeshuvim\n",
    "    for i, poly in enumerate(yeshuvim_polys):\n",
    "        if poly.contains(point):\n",
    "            return yeshuvim_ids[i]\n",
    "        \n",
    "def which_stat_v7(point, yeshuv):\n",
    "    # Get subdistricts to check\n",
    "    stat_areas = yeshuvim_stat_polys[yeshuv]\n",
    "    \n",
    "    # Go over the stat_areas\n",
    "    for i, poly in enumerate(stat_areas):\n",
    "        if type(poly)==str:\n",
    "            print (yeshuv)\n",
    "        if poly.contains(point):\n",
    "            return yeshuvim_stat[yeshuv][i]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Eighth Version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_stat_area_v8(longtitude, latitude):\n",
    "    point = Point(longtitude, latitude)\n",
    "    \n",
    "    # Go over the stat_areas\n",
    "    for i, poly in enumerate(stat_polys):\n",
    "        if poly.contains(point):\n",
    "            return stat_ids[i] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ninth Version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_stat_area_v9(longtitude, latitude):\n",
    "    point = Point(longtitude, latitude)\n",
    "    \n",
    "    # Get the subdistrict\n",
    "    subdistrict = which_subdistrict_v9(point)\n",
    "\n",
    "    # Get the stat area\n",
    "    stat_area = which_stat_v9(point, subdistrict)\n",
    "    \n",
    "    return stat_area\n",
    "\n",
    "def which_subdistrict_v9(point):\n",
    "    # Go over the yeshuvim\n",
    "    for i, poly in enumerate(subdistrict_polys):\n",
    "        if poly.contains(point):\n",
    "            return subdistrict_ids[i]\n",
    "        \n",
    "def which_stat_v9(point, subdistrict=None):\n",
    "    # Get subdistricts to check\n",
    "    if subdistrict:\n",
    "        stat_areas = subdistrict_stat_polys[subdistrict]\n",
    "    else:\n",
    "        stat_areas = stat_polys_singles\n",
    "     \n",
    "    # Go over the stat_areas\n",
    "    for i, poly in enumerate(stat_areas):\n",
    "        if poly.contains(point):\n",
    "            return subdistrict_stat[subdistrict][i]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Time Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "loc_data = pd.read_csv('../data/samples/sample_1+2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34.7736943535 32.0803662605\n"
     ]
    }
   ],
   "source": [
    "lon ,lat = loc_data[['longtitude', 'latitude']].iloc[0]\n",
    "print(lon, lat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### One sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "lon, lat = loc_data.sample()[['longtitude', 'latitude']].iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 loops, best of 3: 10.4 ms per loop\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "get_stat_area_v1(lon, lat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 loops, best of 3: 21 ms per loop\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "get_stat_area_v2(lon, lat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 loops, best of 3: 19.9 ms per loop\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "get_stat_area_v3(lon, lat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 loops, best of 3: 5.11 ms per loop\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "get_stat_area_v4(lon, lat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 loops, best of 3: 5.72 ms per loop\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "get_stat_area_v5(lon, lat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 loops, best of 3: 5.25 ms per loop\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "get_stat_area_v6(lon, lat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 loops, best of 3: 3.51 ms per loop\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "get_stat_area_v7(lon, lat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 loops, best of 3: 10.5 ms per loop\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "get_stat_area_v8(lon, lat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 loops, best of 3: 3.43 ms per loop\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "get_stat_area_v9(lon, lat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 loops, best of 3: 22.3 ms per loop\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "nafot.borders.which_stat_area_wgs(lon, lat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Few samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = loc_data.sample(100).copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 loops, best of 3: 106 ms per loop\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "data['stat_area'] = data.apply(lambda row: get_stat_area_v1(row.longtitude, row.latitude),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 loop, best of 3: 208 ms per loop\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "data['stat_area'] = data.apply(lambda row: get_stat_area_v2(row.longtitude, row.latitude),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 loop, best of 3: 196 ms per loop\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "data['stat_area'] = data.apply(lambda row: get_stat_area_v3(row.longtitude, row.latitude),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 loops, best of 3: 70.7 ms per loop\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "data['stat_area'] = data.apply(lambda row: get_stat_area_v4(row.longtitude, row.latitude),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 loops, best of 3: 62.2 ms per loop\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "data['stat_area'] = data.apply(lambda row: get_stat_area_v5(row.longtitude, row.latitude),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 loops, best of 3: 79.1 ms per loop\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "data['stat_area'] = data.apply(lambda row: get_stat_area_v6(row.longtitude, row.latitude),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%load_ext Cython"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%cython\n",
    "\n",
    "def get_stat_area_v7(longtitude, latitude):\n",
    "    point = Point(longtitude, latitude)\n",
    "    \n",
    "    # Get the yeshuv\n",
    "    yeshuv = which_yeshuv_v7(point)\n",
    "    \n",
    "    if yeshuv:\n",
    "        # Get the stat area\n",
    "        stat_area = which_stat_v7(point, yeshuv)\n",
    "        return stat_area\n",
    "\n",
    "def which_yeshuv_v7(point):\n",
    "    # Go over the yeshuvim\n",
    "    for i, poly in enumerate(yeshuvim_polys):\n",
    "        if poly.contains(point):\n",
    "            return yeshuvim_ids[i]\n",
    "        \n",
    "def which_stat_v7(point, yeshuv):\n",
    "    # Get subdistricts to check\n",
    "    stat_areas = yeshuvim_stat_polys[yeshuv]\n",
    "    \n",
    "    # Go over the stat_areas\n",
    "    for i, poly in enumerate(stat_areas):\n",
    "        if type(poly)==str:\n",
    "            print (yeshuv)\n",
    "        if poly.contains(point):\n",
    "            return yeshuvim_stat[yeshuv][i]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 loop, best of 3: 534 ms per loop\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "data['stat_area'] = data.apply(lambda row: get_stat_area_v7(row.longtitude, row.latitude),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " "
     ]
    }
   ],
   "source": [
    "% prun -l 4 data['stat_area'] = data.apply(lambda row: get_stat_area_v7(row.longtitude, row.latitude),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 loops, best of 3: 111 ms per loop\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "data['stat_area'] = data.apply(lambda row: get_stat_area_v8(row.longtitude, row.latitude),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 loops, best of 3: 44.2 ms per loop\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "data['stat_area'] = data.apply(lambda row: get_stat_area_v9(row.longtitude, row.latitude),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 loop, best of 3: 223 ms per loop\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "data['stat_area'] = data.apply(lambda row: nafot.borders.which_stat_area_wgs(row.longtitude, row.latitude),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "points = data[['longtitude', 'latitude']].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'get_stat_area' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-68-6b8b66df07d9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mget_ipython\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun_cell_magic\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'timeit'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m''\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'areas = np.array([])\\nglobal counter\\nfor p in points:\\n    area = get_stat_area(p[0], p[1])\\n    areas = np.append(areas, area)'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32mC:\\Users\\user\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\u001b[0m in \u001b[0;36mrun_cell_magic\u001b[0;34m(self, magic_name, line, cell)\u001b[0m\n\u001b[1;32m   2113\u001b[0m             \u001b[0mmagic_arg_s\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvar_expand\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mline\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstack_depth\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   2114\u001b[0m             \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbuiltin_trap\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2115\u001b[0;31m                 \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmagic_arg_s\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcell\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2116\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   2117\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<decorator-gen-59>\u001b[0m in \u001b[0;36mtimeit\u001b[0;34m(self, line, cell)\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\user\\Anaconda3\\lib\\site-packages\\IPython\\core\\magic.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(f, *a, **k)\u001b[0m\n\u001b[1;32m    186\u001b[0m     \u001b[1;31m# but it's overkill for just that one bit of state.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mmagic_deco\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 188\u001b[0;31m         \u001b[0mcall\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mlambda\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    189\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    190\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcallable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\user\\Anaconda3\\lib\\site-packages\\IPython\\core\\magics\\execution.py\u001b[0m in \u001b[0;36mtimeit\u001b[0;34m(self, line, cell)\u001b[0m\n\u001b[1;32m   1042\u001b[0m             \u001b[0mnumber\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   1043\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m10\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1044\u001b[0;31m                 \u001b[0mtime_number\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtimer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtimeit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnumber\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1045\u001b[0m                 \u001b[0mworst_tuning\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mworst_tuning\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtime_number\u001b[0m \u001b[1;33m/\u001b[0m \u001b[0mnumber\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   1046\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mtime_number\u001b[0m \u001b[1;33m>=\u001b[0m \u001b[1;36m0.2\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\user\\Anaconda3\\lib\\site-packages\\IPython\\core\\magics\\execution.py\u001b[0m in \u001b[0;36mtimeit\u001b[0;34m(self, number)\u001b[0m\n\u001b[1;32m    137\u001b[0m         \u001b[0mgc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdisable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 139\u001b[0;31m             \u001b[0mtiming\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minner\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mit\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtimer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    140\u001b[0m         \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mgcold\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<magic-timeit>\u001b[0m in \u001b[0;36minner\u001b[0;34m(_it, _timer)\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'get_stat_area' is not defined"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "areas = np.array([])\n",
    "global counter\n",
    "for p in points:\n",
    "    area = get_stat_area(p[0], p[1])\n",
    "    areas = np.append(areas, area)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the imsi list\n",
    "imsi_list = pd.unique(loc_data.imsi)\n",
    "\n",
    "# Get only \"active\" users\n",
    "df = loc_data[['imsi', 'halfhouridx']].groupby('imsi').count()\n",
    "imsi_active = df[df.halfhouridx>100].copy().index.values\n",
    "\n",
    "# Get a sample of users\n",
    "imsi_sm = np.random.choice(imsi_active, size=100, replace=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get a sample of 100 users (~1.3M records)\n",
    "loc_data_sample = loc_data[loc_data.imsi.isin(imsi_sm)][['imsi', 'date_stamp', 'halfhouridx', 'longtitude', 'latitude']].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Add stat area column\n",
    "loc_data_sample['stat_area'] = loc_data_sample.apply(lambda row: get_stat_area_v7(row.longtitude, row.latitude),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Export to csv\n",
    "loc_data_sample.to_csv('sample_100_imsi_with_stat.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loc_data_sample.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = pd.unique(loc_data_sample.stat_area)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ids = gdf.index.values\n",
    "ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count = 0\n",
    "lll = []\n",
    "for i,y in yeshuvim_stat.items():\n",
    "    if y.size <=1:\n",
    "        lll.append(i)\n",
    "        count+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf.loc[10034]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(lll)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in a:\n",
    "    if i not in ids:\n",
    "        print ((i-1)/10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yeshuvim_stat[3784]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loc_data_sample[loc_data_sample.stat_area == 100341.0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loc_data_sample[loc_data_sample.stat_area.isnull()].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('./222', gdf.index.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf.index.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loc_data = pd.read_csv('../data/samples/sample_1+2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sm = loc_data.sample(1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sm.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sm['DistrictCode'] = sm.apply(lambda row: which_district(row.longtitude, row.latitude), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sm.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "point = Point(31.922043, 34.873502)\n",
    "point2 = Point(31.92312, 34.87234)\n",
    "poly = stat_areas_gdf.iloc[2][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cascaded_union(gdf.geometry.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cascaded_union([poly for poly in district_polygons.values()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cascaded_union([district_polygons[1], district_polygons[2]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subdistrict_polygons[44]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "district_polygons[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "districts_gdf.loc[1:1].plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OLD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def which_district(longtitude, latitude):\n",
    "# # convert coordinates and create Point object\n",
    "#     x, y = nafot.wgs_to_itm(longtitude, latitude)\n",
    "#     point = Point(x, y)\n",
    "    \n",
    "#     for i, row in districts_gdf.iterrows():\n",
    "#         if row.geometry.contains(point):\n",
    "#             return i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# def get_stat_area_v7(longtitude, latitude):\n",
    "#     point = Point(longtitude, latitude)\n",
    "    \n",
    "#     # Get the yesahuv\n",
    "#     yeshuv = which_yeshuv_v7(point)\n",
    "    \n",
    "#     if yeshuv:\n",
    "#         # Get the stat area\n",
    "#         stat_area = which_stat_v7(point, yeshuv)\n",
    "#         return stat_area\n",
    "\n",
    "\n",
    "# def which_yeshuv_v7(point):\n",
    "#     # Go over the yeshuvim\n",
    "#     for i, poly in enumerate(yeshuvim_polys):\n",
    "#         if poly.contains(point):\n",
    "#             return yeshuvim_ids[i]\n",
    "        \n",
    "# def which_stat_v7(point, yeshuv):\n",
    "#     # Get subdistricts to check\n",
    "#     stat_areas = yeshuvim_stat_polys[yeshuv]\n",
    "    \n",
    "#     # Go over the stat_areas\n",
    "#     for i, poly in enumerate(stat_areas):\n",
    "#         if type(poly)==str:\n",
    "#             print (yeshuv)\n",
    "#         if poly.contains(point):\n",
    "#             return yeshuvim_stat[yeshuv][i]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hierarchical Search - digits after decimal point"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add a represnting point for each statistical area (the centroid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf['centroid'] = gdf.apply(lambda row: row.geometry.centroid, axis=1)\n",
    "gdf['centroid_lon'] = gdf.apply(lambda row: row.centroid.x, axis=1)\n",
    "gdf['centroid_lat'] = gdf.apply(lambda row: row.centroid.y, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gdf['mindist'] = gdf.apply(lambda row: min([row.centroid.distance(other)\n",
    "#                                                   for other in gdf.centroid.drop(row.name)]), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gdf.mindist.quantile(0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gdf_wgs = nafot.borders.stat_area_wgs_df.copy()\n",
    "# gdf_wgs['centroid'] = gdf_wgs.apply(lambda row: row.geometry.centroid, axis=1)\n",
    "# gdf_wgs['centroid_lon'] = gdf_wgs.apply(lambda row: row.centroid.x, axis=1)\n",
    "# gdf_wgs['centroid_lat'] = gdf_wgs.apply(lambda row: row.centroid.y, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# stat_list = []\n",
    "# prec = 0.0005\n",
    "# for row in gdf_small.itertuples():\n",
    "#     if (abs(lon - row.centroid_lon) < prec) and (abs(lat - row.centroid_lat) < prec):\n",
    "#             stat_list.append(row.Index)\n",
    "# stat_list       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# stat_list = []\n",
    "# prec = 3\n",
    "# for row in gdf_small.itertuples():\n",
    "#     if ((round(lon, prec) == round(row.centroid_lon, prec)) and (round(lat, prec) - round(row.centroid_lat, prec))):\n",
    "#             stat_list.append(row.Index)\n",
    "# stat_list        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# lon, lat = loc_data.sample()[['longtitude', 'latitude']].iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%timeit\n",
    "# stat_list = []\n",
    "# for row in gdf.itertuples():\n",
    "#     if (abs(round(lon, prec) - round(row.centroid_lon, prec) <= 0.001) and \n",
    "#         abs(round(lat, prec) - round(row.centroid_lat, prec)) <= 0.001):\n",
    "#             stat_list.append(row.Index)\n",
    "# len(stat_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def get_stat_area_list(prec=3)\n",
    "#     stat_list = []\n",
    "#     for row in gdf.itertuples():\n",
    "#         if (abs(round(lon, prec) - round(row.centroid_lon, prec) <= 0.01) and \n",
    "#             abs(round(lat, prec) - round(row.centroid_lat, prec)) <= 0.01):\n",
    "#                 stat_list.append(row.Index)\n",
    "#     return stat_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# def get_stat_area_v7(longtitude, latitude):\n",
    "#     point = Point(longtitude, latitude)\n",
    "    \n",
    "#     # Get the yeshuv\n",
    "#     yeshuv = which_yeshuv_v7(point)\n",
    "    \n",
    "#     if yeshuv:\n",
    "#         if yeshuvim_stat[yeshuv].size > 1:\n",
    "#             # Get the stat area\n",
    "#             stat_area = which_stat_v7(point, yeshuv)\n",
    "#             return stat_area\n",
    "#         else:\n",
    "#             return yeshuv*10 +1\n",
    "\n",
    "# def which_yeshuv_v7(point):\n",
    "#     # Go over the yeshuvim\n",
    "#     for i, poly in enumerate(yeshuvim_polys):\n",
    "#         if poly.contains(point):\n",
    "#             return yeshuvim_ids[i]\n",
    "        \n",
    "# def which_stat_v7(point, yeshuv):\n",
    "#     # Get subdistricts to check\n",
    "#     stat_areas = yeshuvim_stat_polys[yeshuv]\n",
    "    \n",
    "#     # Go over the stat_areas\n",
    "#     for i, poly in enumerate(stat_areas):\n",
    "#         if type(poly)==str:\n",
    "#             print (yeshuv)\n",
    "#         if poly.contains(point):\n",
    "#             return yeshuvim_stat[yeshuv][i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gdf.to_file('./ss')"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
